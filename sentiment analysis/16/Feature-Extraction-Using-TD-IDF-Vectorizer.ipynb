{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bcce6e5",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color: #856ff8; padding: 10px;\">\n",
    "    <h2 style=\"font-weight: bold;\">OUTLINE</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96e1e20",
   "metadata": {},
   "source": [
    "- Importing Various Modules\n",
    "- Loading Dataset\n",
    "- Training, Development and Testing Phase\n",
    "- Feature Extraction Using TD-IDF\n",
    "  - Unigram\n",
    "  - Bigram\n",
    "  - Trigram\n",
    "- Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e79824d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color: yellow; padding: 10px;\">\n",
    "    <h2 style=\"font-weight: bold;\">IMPORTING VARIOUS MODULES</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e68c455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from time import time\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b08987",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color: yellow; padding: 10px;\">\n",
    "    <h2 style=\"font-weight: bold;\">LOADING DATASET</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03cc3109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset with no columns titles and with latin encoding \n",
    "twitter_data = pd.read_csv('twitter_sentiment_data_cleaned.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c08bfa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the data has no column titles, we will add our own\n",
    "twitter_data.columns = ['sentiment', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1e5f00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3b5ca_row0_col0, #T_3b5ca_row0_col1, #T_3b5ca_row1_col0, #T_3b5ca_row1_col1, #T_3b5ca_row2_col0, #T_3b5ca_row2_col1, #T_3b5ca_row3_col0, #T_3b5ca_row3_col1, #T_3b5ca_row4_col0, #T_3b5ca_row4_col1 {\n",
       "  background-color: #E9F6E2;\n",
       "  color: black;\n",
       "  border-color: #8b8c8c;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3b5ca\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3b5ca_level0_col0\" class=\"col_heading level0 col0\" >sentiment</th>\n",
       "      <th id=\"T_3b5ca_level0_col1\" class=\"col_heading level0 col1\" >text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3b5ca_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3b5ca_row0_col0\" class=\"data row0 col0\" >4</td>\n",
       "      <td id=\"T_3b5ca_row0_col1\" class=\"data row0 col1\" >is lookin ward to a long weekend really dont want to go to work day tho x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b5ca_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3b5ca_row1_col0\" class=\"data row1 col0\" >4</td>\n",
       "      <td id=\"T_3b5ca_row1_col1\" class=\"data row1 col1\" >myweakness is music and i live to meet the people who make it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b5ca_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_3b5ca_row2_col0\" class=\"data row2 col0\" >4</td>\n",
       "      <td id=\"T_3b5ca_row2_col1\" class=\"data row2 col1\" >figured out the internet on my new ipod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b5ca_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_3b5ca_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_3b5ca_row3_col1\" class=\"data row3 col1\" >can not wait to worship with you guys tonight it ll be so much fun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b5ca_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_3b5ca_row4_col0\" class=\"data row4 col0\" >4</td>\n",
       "      <td id=\"T_3b5ca_row4_col1\" class=\"data row4 col1\" >congrats james i m sure the book is going to be a huge success</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23385af1d20>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first 5 rows of the dataframe.\n",
    "twitter_data.head().style.set_properties(**{'background-color': '#E9F6E2','color': 'black','border-color': '#8b8c8c'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e814332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fae76_row0_col0, #T_fae76_row0_col1, #T_fae76_row1_col0, #T_fae76_row1_col1, #T_fae76_row2_col0, #T_fae76_row2_col1, #T_fae76_row3_col0, #T_fae76_row3_col1, #T_fae76_row4_col0, #T_fae76_row4_col1 {\n",
       "  background-color: #E9F6E2;\n",
       "  color: black;\n",
       "  border-color: #8b8c8c;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fae76\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fae76_level0_col0\" class=\"col_heading level0 col0\" >sentiment</th>\n",
       "      <th id=\"T_fae76_level0_col1\" class=\"col_heading level0 col1\" >text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fae76_level0_row0\" class=\"row_heading level0 row0\" >399995</th>\n",
       "      <td id=\"T_fae76_row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "      <td id=\"T_fae76_row0_col1\" class=\"data row0 col1\" >that is he does not know i tweet and i would like keep it that way sorry bad wife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fae76_level0_row1\" class=\"row_heading level0 row1\" >399996</th>\n",
       "      <td id=\"T_fae76_row1_col0\" class=\"data row1 col0\" >0</td>\n",
       "      <td id=\"T_fae76_row1_col1\" class=\"data row1 col1\" >huh what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fae76_level0_row2\" class=\"row_heading level0 row2\" >399997</th>\n",
       "      <td id=\"T_fae76_row2_col0\" class=\"data row2 col0\" >0</td>\n",
       "      <td id=\"T_fae76_row2_col1\" class=\"data row2 col1\" >only thing is im broke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fae76_level0_row3\" class=\"row_heading level0 row3\" >399998</th>\n",
       "      <td id=\"T_fae76_row3_col0\" class=\"data row3 col0\" >0</td>\n",
       "      <td id=\"T_fae76_row3_col1\" class=\"data row3 col1\" >wish i could work from home today nothing will be going on here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fae76_level0_row4\" class=\"row_heading level0 row4\" >399999</th>\n",
       "      <td id=\"T_fae76_row4_col0\" class=\"data row4 col0\" >0</td>\n",
       "      <td id=\"T_fae76_row4_col1\" class=\"data row4 col1\" >i miss you too i was so worried well today s my last day of school b the break glad u feel better love you</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23385af0d60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print bottom 5 rows in the dataframe.\n",
    "twitter_data.tail().style.set_properties(**{'background-color': '#E9F6E2','color': 'black','border-color': '#8b8c8c'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3525fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of data frame: (400000, 2)\n",
      "Number of Rows in the dataframe: 400000\n",
      "Number of Columns in the dataframe: 2\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the DataFrame\n",
    "print(\"The shape of data frame:\", twitter_data.shape)\n",
    "# Print the length (number of rows) of the DataFrame\n",
    "print(\"Number of Rows in the dataframe:\", len(twitter_data))\n",
    "# Print the number of columns in the DataFrame\n",
    "print(\"Number of Columns in the dataframe:\", len(twitter_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7ea0bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400000 entries, 0 to 399999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   sentiment  400000 non-null  int64 \n",
      " 1   text       399187 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "twitter_data.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abc4dbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data['sentiment'] = twitter_data['sentiment'].map({0:0,4:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "280c464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ee72fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 399187 entries, 0 to 399999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   sentiment  399187 non-null  int64 \n",
      " 1   text       399187 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 9.1+ MB\n"
     ]
    }
   ],
   "source": [
    "twitter_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4245ab32",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color: yellow; padding: 10px;\">\n",
    "    <h2 style=\"font-weight: bold;\">TRAINING, DEVELOPMENT AND TESTING PHASE</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc03c51",
   "metadata": {},
   "source": [
    "We will split the data into three sections: train, development and test. Our chosen ratio is 98/1/1 i.e. 98% for the training set, 1% for the development set and 1% for the testing set.\n",
    "* Train set: The dataset used for learning\n",
    "* Development Set: A validation/development dataset is a sample of data held back from training your model that is used to give an estimate of model skill while tuning modelâ€™s hyperparameters.\n",
    "* Test Set: The dataset used to assess the performance of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aab3f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all other columns except the target variable\n",
    "x = twitter_data['text'] \n",
    "# Define the target variable\n",
    "y = twitter_data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "629365c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size = 0.02, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaa2b060",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, \n",
    "                                                              test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571f6fa9",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color: yellow; padding: 10px;\">\n",
    "    <h2 style=\"font-weight: bold;\">FEATURE EXTRACTION USING TF-IDF</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410a70c0",
   "metadata": {},
   "source": [
    "**Term Frequency** measures how frequently a term occurs in a document. Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length or the total number of terms in the document as a way of normalization: \n",
    "\n",
    "$$TF(t) = \\frac{\\text{Number of times term t appears in a document}}{\\text{Total number of terms in the document}}$$\n",
    "\n",
    "**Inverse Document Frequency** measures how important a term is. While computing TF, all terms are considered equally important. However it is known that certain terms, such as \"is\", \"of\", and \"that\", may appear a lot of times but have little importance. Thus we need to weigh down the frequent terms while scale up the rare ones, by computing the following: \n",
    "\n",
    "$$IDF(t) = \\log_e{\\frac{\\text{Total number of documents}} {\\text{Number of documents with term t in it}}}$$\n",
    "\n",
    "Combining these two, we get TF-IDF.\n",
    "\n",
    "$$TF-IDF(t) = {TF(t)}\\times{IDF(t)}$$\n",
    "\n",
    "The higher the TFIDF score, the rarer the term and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dac7dd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_accuracy = 0\n",
    "def accuracy_summary(pipeline, x_train, y_train, x_test, y_test):\n",
    "    if len(x_test[y_test==0])/len(x_test)>0.5:\n",
    "        null_accuracy = len(x_test[y_test==0])/len(x_test)\n",
    "    else:\n",
    "        null_accuracy = 1 - len(x_test[y_test==0])/len(x_test)\n",
    "    t0 = time()\n",
    "    sentiment_fit = pipeline.fit(x_train, y_train)\n",
    "    y_pred = sentiment_fit.predict(x_test)\n",
    "    train_test_time = time() - t0\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Null accuracy: {0:.2f}%\".format(null_accuracy*100))\n",
    "    print(\"Accuracy: {0:.2f}%\".format(accuracy*100))\n",
    "    if accuracy>null_accuracy:\n",
    "        print(\"Model is {0:.2f}% more accurate than null accuracy\".format((accuracy-null_accuracy)*100))\n",
    "    elif accuracy==null_accuracy:\n",
    "        print(\"Model has the same accuracy as null accuracy\")\n",
    "    else:\n",
    "        print(\"Model is {0:.2f}% less accurate than null accuracy\".format((null_accuracy-accuracy)*100))\n",
    "    print(\"Train and test time: {0:.2f}s\".format(train_test_time))\n",
    "    print(\"-\"*50)\n",
    "    return accuracy, train_test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4511342",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "lr = LogisticRegression()\n",
    "n_features = np.arange(10000, 100001, 10000)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97038f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nfeature_accuracy_checker(vectorizer = tfidf, n_features = n_features, stop_words = None, \n",
    "                              ngram_range = (1,1), classifier = lr):\n",
    "    result = []\n",
    "    print(classifier, \"\\n\")\n",
    "    for n in n_features:\n",
    "        vectorizer.set_params(stop_words = stop_words, max_features = n, ngram_range=ngram_range)\n",
    "        checker_pipeline = Pipeline([('vectorizer', vectorizer), ('classifier', classifier)])\n",
    "        print(\"Validation result for {0} features\".format(n))\n",
    "        nfeature_accuracy, ttime = accuracy_summary(checker_pipeline, x_train, y_train, x_validation, y_validation)\n",
    "        result.append((n, nfeature_accuracy, ttime))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f92a788",
   "metadata": {},
   "source": [
    "<br>\n",
    "<span style=\"color: yellow; background-color: black; font-weight: bold; padding: 5px; font-size: 32px;\"> UNIGRAM </span>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bb331a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT FOR UNIGRAM\n",
      "\n",
      "LogisticRegression() \n",
      "\n",
      "Validation result for 10000 features\n",
      "Null accuracy: 51.13%\n",
      "Accuracy: 79.33%\n",
      "Model is 28.21% more accurate than null accuracy\n",
      "Train and test time: 10.07s\n",
      "--------------------------------------------------\n",
      "Validation result for 20000 features\n",
      "Null accuracy: 51.13%\n",
      "Accuracy: 79.21%\n",
      "Model is 28.08% more accurate than null accuracy\n",
      "Train and test time: 12.93s\n",
      "--------------------------------------------------\n",
      "Validation result for 30000 features\n",
      "Null accuracy: 51.13%\n",
      "Accuracy: 79.26%\n",
      "Model is 28.13% more accurate than null accuracy\n",
      "Train and test time: 13.64s\n",
      "--------------------------------------------------\n",
      "Validation result for 40000 features\n",
      "Null accuracy: 51.13%\n",
      "Accuracy: 79.56%\n",
      "Model is 28.43% more accurate than null accuracy\n",
      "Train and test time: 12.56s\n",
      "--------------------------------------------------\n",
      "Validation result for 50000 features\n",
      "Null accuracy: 51.13%\n",
      "Accuracy: 79.33%\n",
      "Model is 28.21% more accurate than null accuracy\n",
      "Train and test time: 11.68s\n",
      "--------------------------------------------------\n",
      "Validation result for 60000 features\n",
      "Null accuracy: 51.13%\n",
      "Accuracy: 79.43%\n",
      "Model is 28.31% more accurate than null accuracy\n",
      "Train and test time: 13.89s\n",
      "--------------------------------------------------\n",
      "Validation result for 70000 features\n",
      "Null accuracy: 51.13%\n",
      "Accuracy: 79.33%\n",
      "Model is 28.21% more accurate than null accuracy\n",
      "Train and test time: 11.64s\n",
      "--------------------------------------------------\n",
      "Validation result for 80000 features\n",
      "Null accuracy: 51.13%\n",
      "Accuracy: 79.36%\n",
      "Model is 28.23% more accurate than null accuracy\n",
      "Train and test time: 13.20s\n",
      "--------------------------------------------------\n",
      "Validation result for 90000 features\n",
      "Null accuracy: 51.13%\n",
      "Accuracy: 79.33%\n",
      "Model is 28.21% more accurate than null accuracy\n",
      "Train and test time: 11.56s\n",
      "--------------------------------------------------\n",
      "Validation result for 100000 features\n",
      "Null accuracy: 51.13%\n",
      "Accuracy: 79.31%\n",
      "Model is 28.18% more accurate than null accuracy\n",
      "Train and test time: 12.74s\n",
      "--------------------------------------------------\n",
      "CPU times: total: 1min 39s\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"RESULT FOR UNIGRAM\\n\")\n",
    "feature_result_ug_t = nfeature_accuracy_checker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65336434",
   "metadata": {},
   "source": [
    "<br>\n",
    "<span style=\"color: yellow; background-color: black; font-weight: bold; padding: 5px; font-size: 32px;\"> BIGRAM </span>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd5dbaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT FOR BIGRAM\n",
      "\n",
      "LogisticRegression() \n",
      "\n",
      "Validation result for 10000 features\n",
      "Null accuracy: 51.13%\n",
      "Accuracy: 79.73%\n",
      "Model is 28.61% more accurate than null accuracy\n",
      "Train and test time: 23.66s\n",
      "--------------------------------------------------\n",
      "Validation result for 20000 features\n",
      "Null accuracy: 51.13%\n",
      "Accuracy: 80.54%\n",
      "Model is 29.41% more accurate than null accuracy\n",
      "Train and test time: 22.98s\n",
      "--------------------------------------------------\n",
      "Validation result for 30000 features\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:2\u001b[0m\n",
      "Cell \u001b[1;32mIn[16], line 9\u001b[0m, in \u001b[0;36mnfeature_accuracy_checker\u001b[1;34m(vectorizer, n_features, stop_words, ngram_range, classifier)\u001b[0m\n\u001b[0;32m      7\u001b[0m     checker_pipeline \u001b[38;5;241m=\u001b[39m Pipeline([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvectorizer\u001b[39m\u001b[38;5;124m'\u001b[39m, vectorizer), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, classifier)])\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation result for \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m features\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n))\n\u001b[1;32m----> 9\u001b[0m     nfeature_accuracy, ttime \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchecker_pipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_validation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_validation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend((n, nfeature_accuracy, ttime))\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Cell \u001b[1;32mIn[14], line 8\u001b[0m, in \u001b[0;36maccuracy_summary\u001b[1;34m(pipeline, x_train, y_train, x_test, y_test)\u001b[0m\n\u001b[0;32m      6\u001b[0m     null_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(x_test[y_test\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(x_test)\n\u001b[0;32m      7\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m----> 8\u001b[0m sentiment_fit \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m sentiment_fit\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[0;32m     10\u001b[0m train_test_time \u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m-\u001b[39m t0\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\pipeline.py:469\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \n\u001b[0;32m    428\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and sequentially transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    468\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m--> 469\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\pipeline.py:406\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, routed_params)\u001b[0m\n\u001b[0;32m    404\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    405\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 406\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\memory.py:312\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\pipeline.py:1310\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m   1309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1310\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1312\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m   1313\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m   1314\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:2091\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2084\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2085\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2086\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2087\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2088\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2089\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2090\u001b[0m )\n\u001b[1;32m-> 2091\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2092\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2093\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2094\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:1372\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1364\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1369\u001b[0m             )\n\u001b[0;32m   1370\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1372\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1375\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:1261\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m analyze(doc):\n\u001b[0;32m   1260\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1261\u001b[0m         feature_idx \u001b[38;5;241m=\u001b[39m \u001b[43mvocabulary\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1262\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m feature_idx \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m feature_counter:\n\u001b[0;32m   1263\u001b[0m             feature_counter[feature_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"RESULT FOR BIGRAM\\n\")\n",
    "feature_result_bg_t = nfeature_accuracy_checker(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638c93a0",
   "metadata": {},
   "source": [
    "<br>\n",
    "<span style=\"color: yellow; background-color: black; font-weight: bold; padding: 5px; font-size: 32px;\"> TRIGRAM </span>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "605f7e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT FOR TRIGRAM\n",
      "\n",
      "LogisticRegression() \n",
      "\n",
      "Validation result for 10000 features\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:2\u001b[0m\n",
      "Cell \u001b[1;32mIn[16], line 9\u001b[0m, in \u001b[0;36mnfeature_accuracy_checker\u001b[1;34m(vectorizer, n_features, stop_words, ngram_range, classifier)\u001b[0m\n\u001b[0;32m      7\u001b[0m     checker_pipeline \u001b[38;5;241m=\u001b[39m Pipeline([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvectorizer\u001b[39m\u001b[38;5;124m'\u001b[39m, vectorizer), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, classifier)])\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation result for \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m features\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n))\n\u001b[1;32m----> 9\u001b[0m     nfeature_accuracy, ttime \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchecker_pipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_validation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_validation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend((n, nfeature_accuracy, ttime))\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Cell \u001b[1;32mIn[14], line 8\u001b[0m, in \u001b[0;36maccuracy_summary\u001b[1;34m(pipeline, x_train, y_train, x_test, y_test)\u001b[0m\n\u001b[0;32m      6\u001b[0m     null_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(x_test[y_test\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(x_test)\n\u001b[0;32m      7\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m----> 8\u001b[0m sentiment_fit \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m sentiment_fit\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[0;32m     10\u001b[0m train_test_time \u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m-\u001b[39m t0\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\pipeline.py:469\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \n\u001b[0;32m    428\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and sequentially transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    468\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m--> 469\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\pipeline.py:406\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, routed_params)\u001b[0m\n\u001b[0;32m    404\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    405\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 406\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\memory.py:312\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\pipeline.py:1310\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m   1309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1310\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1312\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m   1313\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m   1314\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:2091\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2084\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2085\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2086\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2087\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2088\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2089\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2090\u001b[0m )\n\u001b[1;32m-> 2091\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2092\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2093\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2094\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:1372\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1364\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1369\u001b[0m             )\n\u001b[0;32m   1370\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1372\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1375\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:1271\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1268\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1270\u001b[0m     j_indices\u001b[38;5;241m.\u001b[39mextend(feature_counter\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m-> 1271\u001b[0m     \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_counter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1272\u001b[0m     indptr\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(j_indices))\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fixed_vocab:\n\u001b[0;32m   1275\u001b[0m     \u001b[38;5;66;03m# disable defaultdict behaviour\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"RESULT FOR TRIGRAM\\n\")\n",
    "feature_result_tg_t = nfeature_accuracy_checker(ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f97a972",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_result_bg_t' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m feature_plot_ug_t \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(feature_result_ug_t, columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_test_time\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m feature_plot_bg_t \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mfeature_result_bg_t\u001b[49m, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_test_time\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m feature_plot_tg_t \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(feature_result_tg_t, columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_test_time\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feature_result_bg_t' is not defined"
     ]
    }
   ],
   "source": [
    "feature_plot_ug_t = pd.DataFrame(feature_result_ug_t, columns = ['nfeatures', 'validation_accuracy', 'train_test_time'])\n",
    "feature_plot_bg_t = pd.DataFrame(feature_result_bg_t, columns=['nfeatures', 'validation_accuracy', 'train_test_time'])\n",
    "feature_plot_tg_t = pd.DataFrame(feature_result_tg_t, columns = ['nfeatures', 'validation_accuracy', 'train_test_time'])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plotting Unigram TFIDF\n",
    "plt.plot(feature_plot_ug_t.nfeatures, feature_plot_ug_t.validation_accuracy, label='Unigram TFIDF', color='orange', marker='o', linestyle=':')\n",
    "\n",
    "# Plotting Bigram TFIDF\n",
    "plt.plot(feature_plot_bg_t.nfeatures, feature_plot_bg_t.validation_accuracy, label='Bigram TFIDF', color='gold', marker='s', linestyle=':')\n",
    "\n",
    "# Plotting Trigram TFIDF\n",
    "plt.plot(feature_plot_tg_t.nfeatures, feature_plot_tg_t.validation_accuracy, label='Trigram TFIDF', color='blue', marker='^', linestyle=':')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title('N-gram (1-3) Accuracy')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "\n",
    "# Adding grid for better readability\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adding legend\n",
    "plt.legend()\n",
    "\n",
    "# Adding a tight layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccf386d",
   "metadata": {},
   "source": [
    "For bigram and trigram, TfidfVectorizer gives better performance than CountVectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee8f472",
   "metadata": {},
   "source": [
    "Bigram TfidfVectorizer at 90000 features gives the highest validation accuracy at 82.45%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7163d91",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color: yellow; padding: 10px;\">\n",
    "    <h2 style=\"font-weight: bold;\">DATA MODELING</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29aca756",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Ridge Classifier', 'Logistic Regression', 'Stochastic Gradient Descent', 'Multinomial NB', 'Bernoulli NB']\n",
    "classifiers = [\n",
    "    RidgeClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(),\n",
    "    MultinomialNB(),\n",
    "    BernoulliNB(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "359c87e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_clf = zip(names, classifiers)\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "025a52bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_comparator(vectorizer = tfidf, n_features=10000, stop_words=None, ngram_range=(1,1), classifier=zipped_clf):\n",
    "    result = []\n",
    "    vectorizer.set_params(stop_words=stop_words, ngram_range=ngram_range, max_features=n_features)\n",
    "    for n, c in classifier:\n",
    "        pipeline = Pipeline([('vectorizer', vectorizer), ('classifier', c)])\n",
    "        print('Validation result for {}'.format(n), c)\n",
    "        clf_accuracy, ttime = accuracy_summary(pipeline, x_train, y_train, x_validation, y_validation)\n",
    "        result.append((n, clf_accuracy, ttime))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b584562d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation result for Ridge Classifier RidgeClassifier()\n",
      "Null accuracy: 51.13%\n",
      "Accuracy: 80.01%\n",
      "Model is 28.88% more accurate than null accuracy\n",
      "Train and test time: 21.72s\n",
      "--------------------------------------------------\n",
      "Validation result for Logistic Regression LogisticRegression()\n",
      "Null accuracy: 51.13%\n",
      "Accuracy: 80.86%\n",
      "Model is 29.73% more accurate than null accuracy\n",
      "Train and test time: 25.98s\n",
      "--------------------------------------------------\n",
      "Validation result for Stochastic Gradient Descent SGDClassifier()\n",
      "Null accuracy: 51.13%\n",
      "Accuracy: 78.43%\n",
      "Model is 27.30% more accurate than null accuracy\n",
      "Train and test time: 18.30s\n",
      "--------------------------------------------------\n",
      "Validation result for Multinomial NB MultinomialNB()\n",
      "Null accuracy: 51.13%\n",
      "Accuracy: 78.86%\n",
      "Model is 27.73% more accurate than null accuracy\n",
      "Train and test time: 17.48s\n",
      "--------------------------------------------------\n",
      "Validation result for Bernoulli NB BernoulliNB()\n",
      "Null accuracy: 51.13%\n",
      "Accuracy: 78.83%\n",
      "Model is 27.71% more accurate than null accuracy\n",
      "Train and test time: 18.54s\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "bigram_comparison = classifier_comparator(n_features=90000, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7449eeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Classifier', 'Accuracy', 'Time']\n",
    "df = pd.DataFrame(bigram_comparison, columns = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9418b484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b3e7b_row0_col0, #T_b3e7b_row0_col1, #T_b3e7b_row0_col2, #T_b3e7b_row1_col0, #T_b3e7b_row1_col1, #T_b3e7b_row1_col2, #T_b3e7b_row2_col0, #T_b3e7b_row2_col1, #T_b3e7b_row2_col2, #T_b3e7b_row3_col0, #T_b3e7b_row3_col1, #T_b3e7b_row3_col2, #T_b3e7b_row4_col0, #T_b3e7b_row4_col1, #T_b3e7b_row4_col2 {\n",
       "  background-color: #E9F6E2;\n",
       "  color: black;\n",
       "  border-color: #8b8c8c;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b3e7b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b3e7b_level0_col0\" class=\"col_heading level0 col0\" >Classifier</th>\n",
       "      <th id=\"T_b3e7b_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_b3e7b_level0_col2\" class=\"col_heading level0 col2\" >Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b3e7b_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_b3e7b_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_b3e7b_row0_col1\" class=\"data row0 col1\" >0.808617</td>\n",
       "      <td id=\"T_b3e7b_row0_col2\" class=\"data row0 col2\" >25.984384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3e7b_level0_row1\" class=\"row_heading level0 row1\" >0</th>\n",
       "      <td id=\"T_b3e7b_row1_col0\" class=\"data row1 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_b3e7b_row1_col1\" class=\"data row1 col1\" >0.800100</td>\n",
       "      <td id=\"T_b3e7b_row1_col2\" class=\"data row1 col2\" >21.721810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3e7b_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_b3e7b_row2_col0\" class=\"data row2 col0\" >Multinomial NB</td>\n",
       "      <td id=\"T_b3e7b_row2_col1\" class=\"data row2 col1\" >0.788577</td>\n",
       "      <td id=\"T_b3e7b_row2_col2\" class=\"data row2 col2\" >17.478353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3e7b_level0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "      <td id=\"T_b3e7b_row3_col0\" class=\"data row3 col0\" >Bernoulli NB</td>\n",
       "      <td id=\"T_b3e7b_row3_col1\" class=\"data row3 col1\" >0.788327</td>\n",
       "      <td id=\"T_b3e7b_row3_col2\" class=\"data row3 col2\" >18.538436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3e7b_level0_row4\" class=\"row_heading level0 row4\" >2</th>\n",
       "      <td id=\"T_b3e7b_row4_col0\" class=\"data row4 col0\" >Stochastic Gradient Descent</td>\n",
       "      <td id=\"T_b3e7b_row4_col1\" class=\"data row4 col1\" >0.784319</td>\n",
       "      <td id=\"T_b3e7b_row4_col2\" class=\"data row4 col2\" >18.296294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e5da520bd0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='Accuracy', ascending=False).style.set_properties(**{'background-color': '#E9F6E2','color': 'black','border-color': '#8b8c8c'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
